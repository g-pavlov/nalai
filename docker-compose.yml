services:
  nalai:
    build:
      context: .
      dockerfile: Dockerfile.dev
    ports:
      - "8000:8080"
    volumes:
      # Development: Mount source code for hot reload
      - ./src/nalai:/app/nalai
      # Production-like: Mount logs and data
      - ./logs:/app/logs
      - ./data:/app/data
    env_file:
      - .env
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    depends_on:
      - ollama
      - ecommerce-mock



  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "${OLLAMA_PORT:-11435}:11434"
    volumes:
      # Production-like: Persistent model storage
      - ollama_data:/root/.ollama
      # Development: Mount host models for faster startup
      - ./models:/models
    env_file:
      - .env
    # Production-like resource limits
    deploy:
      resources:
        limits:
          memory: 12G
          cpus: '10.0'
        reservations:
          memory: 8G
          cpus: '8.0'
    # Performance optimizations
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  ecommerce-mock:
    build:
      context: ./demo
      dockerfile: Dockerfile
    container_name: ecommerce-mock
    ports:
      - "8001:8000"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  nalai-ui:
    image: nginx:alpine
    container_name: nalai-ui
    ports:
      - "3001:80"
    volumes:
      - ./demo/ui/ai-chat.html:/usr/share/nginx/html/index.html:ro
    restart: unless-stopped

networks:
  default:
    driver: bridge

volumes:
  ollama_data:
    driver: local
